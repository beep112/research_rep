<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Transformer fundamentals: gpt/working_gpt.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Transformer fundamentals
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('working__gpt_8py_source.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">working_gpt.py</div></div>
</div><!--header-->
<div class="contents">
<a href="working__gpt_8py.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html">    1</a></span><span class="keyword">import</span> torch</div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span> </div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment"># hyperparameters</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a4ab546baad18775c66fe9d071fa35006">    6</a></span>batch_size = 64  <span class="comment"># how many independent sequences will we process in parallel?</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a8f7e4abb942f2bf105fa9dfb3563d2ee">    7</a></span>block_size = 256  <span class="comment"># what is the maximum context length for predictions?</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#ad3875ae4f23c077b7d81b48ea7eefa29">    8</a></span>max_iters = 5000</div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#aecbb4e23835415f4cd684dd09b21edc3">    9</a></span>eval_interval = 500</div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a68572ed0db77a94a06e48472ed57f72a">   10</a></span>learning_rate = 3e-4</div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment"># device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="keywordflow">if</span> torch.backends.mps.is_available() <span class="keywordflow">and</span> torch.backends.mps.is_built():</div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a95b465dd3d969fb90d08dc07ed3bb088">   13</a></span>    device = <span class="stringliteral">&quot;mps&quot;</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment"># check for cuda which should be used because obviously</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="keywordflow">elif</span> torch.cuda.is_available():</div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span>    device = <span class="stringliteral">&quot;cuda&quot;</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="comment"># if now GPU (AMD excluded right now) then just use the CPU</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span>    device = <span class="stringliteral">&quot;cpu&quot;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a2a379db2a26e047b66b883d99749c26f">   21</a></span>eval_iters = 200</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a2f2855b7d41865487d7a4874082d541c">   22</a></span>n_embd = 384</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#ad3eb2b15965905484e89230643744b3c">   23</a></span>n_head = 6</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a8af9255c53d4dece248971f906b89a99">   24</a></span>n_layer = 6</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a1054502bbd7be932fb8819003e749f04">   25</a></span>dropout = 0.2</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="comment"># ------------</span></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span> </div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span>torch.manual_seed(1337)</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span> </div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="comment"># wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt</span></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#aa9c2dca932cc2d34f597cb6c04e700c7">   31</a></span><span class="keyword">with</span> open(<span class="stringliteral">&quot;input.txt&quot;</span>, <span class="stringliteral">&quot;r&quot;</span>, encoding=<span class="stringliteral">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a4ad2800f65f260cdf4090c807a1371b4">   32</a></span>    text = f.read()</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span> </div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="comment"># here are all the unique characters that occur in this text</span></div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a0d4a3a67f437adca9ae5052385c9ca36">   35</a></span>chars = sorted(list(set(text)))</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a54e899d583fd272fcc069268621e10c9">   36</a></span>vocab_size = len(chars)</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span><span class="comment"># create a mapping from characters to integers</span></div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a8f354923303ace8bdbdbbd59f937d9d7">   38</a></span>stoi = {ch: i <span class="keywordflow">for</span> i, ch <span class="keywordflow">in</span> enumerate(chars)}</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#aed8c42cd69d135d320ea8496f36917d7">   39</a></span>itos = {i: ch <span class="keywordflow">for</span> i, ch <span class="keywordflow">in</span> enumerate(chars)}</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a8a25d67becf5f15d2a161adb2894ef34">   40</a></span>encode = <span class="keyword">lambda</span> s: [</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>    stoi[c] <span class="keywordflow">for</span> c <span class="keywordflow">in</span> s</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>]  <span class="comment"># encoder: take a string, output a list of integers</span></div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#af85d2524d40fe93c9994df5eca877ef9">   43</a></span>decode = <span class="keyword">lambda</span> l: <span class="stringliteral">&quot;&quot;</span>.join(</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>    [itos[i] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> l]</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>)  <span class="comment"># decoder: take a list of integers, output a string</span></div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span> </div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span><span class="comment"># Train and test splits</span></div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a65719a8def64272f4b925b4164c78856">   48</a></span>data = torch.tensor(<a class="code hl_variable" href="namespaceworking__gpt.html#a8a25d67becf5f15d2a161adb2894ef34">encode</a>(text), dtype=torch.long)</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a221cf52b7d6a10db629348156c30af39">   49</a></span>n = int(0.9 * len(data))  <span class="comment"># first 90% will be train, rest val</span></div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a1734c9d20c55c89e14f172ba58256141">   50</a></span>train_data = data[:n]</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a927cc8f2598450757506b2ef07336b25">   51</a></span>val_data = data[n:]</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span> </div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span> </div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span><span class="comment"># data loading</span></div>
<div class="foldopen" id="foldopen00055" data-start="" data-end="">
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a537e4314706b5fa0d856cb39a9d5b974">   55</a></span><span class="keyword">def </span><a class="code hl_function" href="namespaceworking__gpt.html#a537e4314706b5fa0d856cb39a9d5b974">get_batch</a>(split):</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>    <span class="comment"># generate a small batch of data of inputs x and targets y</span></div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>    data = train_data <span class="keywordflow">if</span> split == <span class="stringliteral">&quot;train&quot;</span> <span class="keywordflow">else</span> val_data</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>    ix = torch.randint(len(data) - block_size, (batch_size,))</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>    x = torch.stack([data[i : i + block_size] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> ix])</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>    y = torch.stack([data[i + 1 : i + block_size + 1] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> ix])</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>    x, y = x.to(device), y.to(device)</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>    <span class="keywordflow">return</span> x, y</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span> </div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span> </div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span><span class="preprocessor">@torch.no_grad()</span></div>
</div>
<div class="foldopen" id="foldopen00066" data-start="" data-end="">
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a950488ca4171a45450e4e31f044fcaf4">   66</a></span><span class="keyword">def </span><a class="code hl_function" href="namespaceworking__gpt.html#a950488ca4171a45450e4e31f044fcaf4">estimate_loss</a>():</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>    out = {}</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>    model.eval()</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>    <span class="keywordflow">for</span> split <span class="keywordflow">in</span> [<span class="stringliteral">&quot;train&quot;</span>, <span class="stringliteral">&quot;val&quot;</span>]:</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>        losses = torch.zeros(eval_iters)</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>        <span class="keywordflow">for</span> k <span class="keywordflow">in</span> range(eval_iters):</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>            X, Y = <a class="code hl_function" href="namespaceworking__gpt.html#a537e4314706b5fa0d856cb39a9d5b974">get_batch</a>(split)</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>            logits, loss = <a class="code hl_variable" href="namespaceworking__gpt.html#a3a7c1fc46622cfddedb86c002e96a46a">model</a>(X, Y)</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>            losses[k] = loss.item()</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>        out[split] = losses.mean()</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>    model.train()</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>    <span class="keywordflow">return</span> out</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span> </div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span> </div>
</div>
<div class="foldopen" id="foldopen00080" data-start="" data-end="">
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_head.html">   80</a></span><span class="keyword">class </span><a class="code hl_class" href="classworking__gpt_1_1_head.html">Head</a>(nn.Module):</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>    <span class="stringliteral">&quot;&quot;&quot;one head of self-attention&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span> </div>
<div class="foldopen" id="foldopen00083" data-start="" data-end="">
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_head.html#a4a46c27cb063448efb69edd207f28e97">   83</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_head.html#a4a46c27cb063448efb69edd207f28e97">__init__</a>(self, head_size):</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>        super().<a class="code hl_function" href="classworking__gpt_1_1_head.html#a4a46c27cb063448efb69edd207f28e97">__init__</a>()</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_head.html#a12269f8694fe12099c4c2b38458f2f76">   85</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#a12269f8694fe12099c4c2b38458f2f76">key</a> = nn.Linear(n_embd, head_size, bias=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_head.html#a2f006b42180ef31ff92582368f2fe6ca">   86</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#a2f006b42180ef31ff92582368f2fe6ca">query</a> = nn.Linear(n_embd, head_size, bias=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_head.html#a2a84286477e3d9750c6bde3264bacec9">   87</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#a2a84286477e3d9750c6bde3264bacec9">value</a> = nn.Linear(n_embd, head_size, bias=<span class="keyword">False</span>)</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>        self.register_buffer(<span class="stringliteral">&quot;tril&quot;</span>, torch.tril(torch.ones(block_size, block_size)))</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span> </div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_head.html#aba008c97dcdae1abdb3a1dd98d785a73">   90</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#aba008c97dcdae1abdb3a1dd98d785a73">dropout</a> = nn.Dropout(dropout)</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span> </div>
</div>
<div class="foldopen" id="foldopen00092" data-start="" data-end="">
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_head.html#a362d310ec34a91843d2a4b6c997da058">   92</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_head.html#a362d310ec34a91843d2a4b6c997da058">forward</a>(self, x):</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>        <span class="comment"># input of size (batch, time-step, channels)</span></div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>        <span class="comment"># output of size (batch, time-step, head size)</span></div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>        B, T, C = x.shape</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>        k = self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#a12269f8694fe12099c4c2b38458f2f76">key</a>(x)  <span class="comment"># (B,T,hs)</span></div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>        q = self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#a2f006b42180ef31ff92582368f2fe6ca">query</a>(x)  <span class="comment"># (B,T,hs)</span></div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>        <span class="comment"># compute attention scores (&quot;affinities&quot;)</span></div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>        wei = (</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>            q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>        )  <span class="comment"># (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)</span></div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(<span class="stringliteral">&quot;-inf&quot;</span>))  <span class="comment"># (B, T, T)</span></div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>        wei = F.softmax(wei, dim=-1)  <span class="comment"># (B, T, T)</span></div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>        wei = self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#aba008c97dcdae1abdb3a1dd98d785a73">dropout</a>(wei)</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>        <span class="comment"># perform the weighted aggregation of the values</span></div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>        v = self.<a class="code hl_variable" href="classworking__gpt_1_1_head.html#a2a84286477e3d9750c6bde3264bacec9">value</a>(x)  <span class="comment"># (B,T,hs)</span></div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>        out = wei @ v  <span class="comment"># (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)</span></div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>        <span class="keywordflow">return</span> out</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span> </div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00111" data-start="" data-end="">
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_multi_head_attention.html">  111</a></span><span class="keyword">class </span><a class="code hl_class" href="classworking__gpt_1_1_multi_head_attention.html">MultiHeadAttention</a>(nn.Module):</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>    <span class="stringliteral">&quot;&quot;&quot;multiple heads of self-attention in parallel&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span> </div>
<div class="foldopen" id="foldopen00114" data-start="" data-end="">
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_multi_head_attention.html#aee4760ff4d175b2ba2d591c33e612b2b">  114</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_multi_head_attention.html#aee4760ff4d175b2ba2d591c33e612b2b">__init__</a>(self, num_heads, head_size):</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>        super().<a class="code hl_function" href="classworking__gpt_1_1_multi_head_attention.html#aee4760ff4d175b2ba2d591c33e612b2b">__init__</a>()</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_multi_head_attention.html#a6a581eff19023cc386823f3159184ca2">  116</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_multi_head_attention.html#a6a581eff19023cc386823f3159184ca2">heads</a> = nn.ModuleList([<a class="code hl_class" href="classworking__gpt_1_1_head.html">Head</a>(head_size) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(num_heads)])</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_multi_head_attention.html#a507050f84e12b4708db81e3e40187c21">  117</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_multi_head_attention.html#a507050f84e12b4708db81e3e40187c21">proj</a> = nn.Linear(head_size * num_heads, n_embd)</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_multi_head_attention.html#a73a6f814bfe5418a8c9c141681ca0b26">  118</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_multi_head_attention.html#a73a6f814bfe5418a8c9c141681ca0b26">dropout</a> = nn.Dropout(dropout)</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span> </div>
</div>
<div class="foldopen" id="foldopen00120" data-start="" data-end="">
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_multi_head_attention.html#a1d8312be9b3438f1d261c634baebd247">  120</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_multi_head_attention.html#a1d8312be9b3438f1d261c634baebd247">forward</a>(self, x):</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>        out = torch.cat([h(x) <span class="keywordflow">for</span> h <span class="keywordflow">in</span> self.<a class="code hl_variable" href="classworking__gpt_1_1_multi_head_attention.html#a6a581eff19023cc386823f3159184ca2">heads</a>], dim=-1)</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>        out = self.<a class="code hl_variable" href="classworking__gpt_1_1_multi_head_attention.html#a73a6f814bfe5418a8c9c141681ca0b26">dropout</a>(self.<a class="code hl_variable" href="classworking__gpt_1_1_multi_head_attention.html#a507050f84e12b4708db81e3e40187c21">proj</a>(out))</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>        <span class="keywordflow">return</span> out</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span> </div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00126" data-start="" data-end="">
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_feed_foward.html">  126</a></span><span class="keyword">class </span><a class="code hl_class" href="classworking__gpt_1_1_feed_foward.html">FeedFoward</a>(nn.Module):</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>    <span class="stringliteral">&quot;&quot;&quot;a simple linear layer followed by a non-linearity&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span> </div>
<div class="foldopen" id="foldopen00129" data-start="" data-end="">
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_feed_foward.html#a4d281ee2a86f1632b7aad53e446f2680">  129</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_feed_foward.html#a4d281ee2a86f1632b7aad53e446f2680">__init__</a>(self, n_embd):</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>        super().<a class="code hl_function" href="classworking__gpt_1_1_feed_foward.html#a4d281ee2a86f1632b7aad53e446f2680">__init__</a>()</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_feed_foward.html#ac1a48723779f00572e5217519e1c28eb">  131</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_feed_foward.html#ac1a48723779f00572e5217519e1c28eb">net</a> = nn.Sequential(</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>            nn.Linear(n_embd, 4 * n_embd),</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>            nn.ReLU(),</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>            nn.Linear(4 * n_embd, n_embd),</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>            nn.Dropout(dropout),</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>        )</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span> </div>
</div>
<div class="foldopen" id="foldopen00138" data-start="" data-end="">
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_feed_foward.html#a92d6bf9882ff2e734975cec4598e9d51">  138</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_feed_foward.html#a92d6bf9882ff2e734975cec4598e9d51">forward</a>(self, x):</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>        <span class="keywordflow">return</span> self.<a class="code hl_variable" href="classworking__gpt_1_1_feed_foward.html#ac1a48723779f00572e5217519e1c28eb">net</a>(x)</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span> </div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00142" data-start="" data-end="">
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_block.html">  142</a></span><span class="keyword">class </span><a class="code hl_class" href="classworking__gpt_1_1_block.html">Block</a>(nn.Module):</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>    <span class="stringliteral">&quot;&quot;&quot;Transformer block: communication followed by computation&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span> </div>
<div class="foldopen" id="foldopen00145" data-start="" data-end="">
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_block.html#a6fd11f02e4b3567560d9c923e02eaa17">  145</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_block.html#a6fd11f02e4b3567560d9c923e02eaa17">__init__</a>(self, n_embd, n_head):</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>        <span class="comment"># n_embd: embedding dimension, n_head: the number of heads we&#39;d like</span></div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>        super().<a class="code hl_function" href="classworking__gpt_1_1_block.html#a6fd11f02e4b3567560d9c923e02eaa17">__init__</a>()</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>        head_size = n_embd // n_head</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_block.html#aa5a75b15c13f5e1ad268693ec197a360">  149</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#aa5a75b15c13f5e1ad268693ec197a360">sa</a> = <a class="code hl_class" href="classworking__gpt_1_1_multi_head_attention.html">MultiHeadAttention</a>(n_head, head_size)</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_block.html#a1dfc3b1a01fca2e5f18f7efdbbe2160d">  150</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#a1dfc3b1a01fca2e5f18f7efdbbe2160d">ffwd</a> = <a class="code hl_class" href="classworking__gpt_1_1_feed_foward.html">FeedFoward</a>(n_embd)</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_block.html#ad3b46f9f73185d03d53d0a5f94ce42f7">  151</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#ad3b46f9f73185d03d53d0a5f94ce42f7">ln1</a> = nn.LayerNorm(n_embd)</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_block.html#a75a58c24072cdc9ca6d32293751d06fb">  152</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#a75a58c24072cdc9ca6d32293751d06fb">ln2</a> = nn.LayerNorm(n_embd)</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span> </div>
</div>
<div class="foldopen" id="foldopen00154" data-start="" data-end="">
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_block.html#a89af2932fe8018bea194bc35fe7430b5">  154</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_block.html#a89af2932fe8018bea194bc35fe7430b5">forward</a>(self, x):</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>        x = x + self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#aa5a75b15c13f5e1ad268693ec197a360">sa</a>(self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#ad3b46f9f73185d03d53d0a5f94ce42f7">ln1</a>(x))</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>        x = x + self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#a1dfc3b1a01fca2e5f18f7efdbbe2160d">ffwd</a>(self.<a class="code hl_variable" href="classworking__gpt_1_1_block.html#a75a58c24072cdc9ca6d32293751d06fb">ln2</a>(x))</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>        <span class="keywordflow">return</span> x</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span> </div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span> </div>
</div>
</div>
<div class="foldopen" id="foldopen00160" data-start="" data-end="">
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html">  160</a></span><span class="keyword">class </span><a class="code hl_class" href="classworking__gpt_1_1_g_p_t_language_model.html">GPTLanguageModel</a>(nn.Module):</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span> </div>
<div class="foldopen" id="foldopen00162" data-start="" data-end="">
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#ad68ec65316f6521a5109f4a1ec3e7f08">  162</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_g_p_t_language_model.html#ad68ec65316f6521a5109f4a1ec3e7f08">__init__</a>(self):</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>        super().<a class="code hl_function" href="classworking__gpt_1_1_g_p_t_language_model.html#ad68ec65316f6521a5109f4a1ec3e7f08">__init__</a>()</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>        <span class="comment"># each token directly reads off the logits for the next token from a lookup table</span></div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#aaf794f5b1d39817791387f5b51b0e547">  165</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#aaf794f5b1d39817791387f5b51b0e547">token_embedding_table</a> = nn.Embedding(vocab_size, n_embd)</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#a6685d16c7737c65554009ab61b7ce3db">  166</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#a6685d16c7737c65554009ab61b7ce3db">position_embedding_table</a> = nn.Embedding(block_size, n_embd)</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#aaf93fa6e29338a111389f7a6fa0a35d4">  167</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#aaf93fa6e29338a111389f7a6fa0a35d4">blocks</a> = nn.Sequential(</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>            *[<a class="code hl_class" href="classworking__gpt_1_1_block.html">Block</a>(n_embd, n_head=n_head) <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(n_layer)]</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>        )</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#ad739f9605e69c1c30950d27dc9990bc6">  170</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#ad739f9605e69c1c30950d27dc9990bc6">ln_f</a> = nn.LayerNorm(n_embd)  <span class="comment"># final layer norm</span></div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#a3172cb512b0556984b234c639bdc13a3">  171</a></span>        self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#a3172cb512b0556984b234c639bdc13a3">lm_head</a> = nn.Linear(n_embd, vocab_size)</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span> </div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>        <span class="comment"># better init, not covered in the original GPT video, but important, will cover in followup video</span></div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#a6bcdbf1380ac84a5c0db37f4d431db59">  174</a></span>        self.apply(self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#a6bcdbf1380ac84a5c0db37f4d431db59">_init_weights</a>)</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span> </div>
</div>
<div class="foldopen" id="foldopen00176" data-start="" data-end="">
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#a91164941bf00c31ac82263a43edd0b77">  176</a></span>    <span class="keyword">def </span><a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#a6bcdbf1380ac84a5c0db37f4d431db59">_init_weights</a>(self, module):</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>        <span class="keywordflow">if</span> isinstance(module, nn.Linear):</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>            <span class="keywordflow">if</span> module.bias <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>                torch.nn.init.zeros_(module.bias)</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>        <span class="keywordflow">elif</span> isinstance(module, nn.Embedding):</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span> </div>
</div>
<div class="foldopen" id="foldopen00184" data-start="" data-end="">
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#a998f0e786960c0839f009e4613aac5ae">  184</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_g_p_t_language_model.html#a998f0e786960c0839f009e4613aac5ae">forward</a>(self, idx, targets=None):</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>        B, T = idx.shape</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span> </div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>        <span class="comment"># idx and targets are both (B,T) tensor of integers</span></div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>        tok_emb = self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#aaf794f5b1d39817791387f5b51b0e547">token_embedding_table</a>(idx)  <span class="comment"># (B,T,C)</span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>        pos_emb = self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#a6685d16c7737c65554009ab61b7ce3db">position_embedding_table</a>(torch.arange(T, device=device))  <span class="comment"># (T,C)</span></div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>        x = tok_emb + pos_emb  <span class="comment"># (B,T,C)</span></div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>        x = self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#aaf93fa6e29338a111389f7a6fa0a35d4">blocks</a>(x)  <span class="comment"># (B,T,C)</span></div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>        x = self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#ad739f9605e69c1c30950d27dc9990bc6">ln_f</a>(x)  <span class="comment"># (B,T,C)</span></div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>        logits = self.<a class="code hl_variable" href="classworking__gpt_1_1_g_p_t_language_model.html#a3172cb512b0556984b234c639bdc13a3">lm_head</a>(x)  <span class="comment"># (B,T,vocab_size)</span></div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span> </div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>        <span class="keywordflow">if</span> targets <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>            loss = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>            B, T, C = logits.shape</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>            logits = logits.view(B * T, C)</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>            targets = targets.view(B * T)</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>            loss = F.cross_entropy(logits, targets)</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span> </div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>        <span class="keywordflow">return</span> logits, loss</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span> </div>
</div>
<div class="foldopen" id="foldopen00205" data-start="" data-end="">
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno"><a class="line" href="classworking__gpt_1_1_g_p_t_language_model.html#a022aa1f7826738385eb4190fe73db9fc">  205</a></span>    <span class="keyword">def </span><a class="code hl_function" href="classworking__gpt_1_1_g_p_t_language_model.html#a022aa1f7826738385eb4190fe73db9fc">generate</a>(self, idx, max_new_tokens):</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>        <span class="comment"># idx is (B, T) array of indices in the current context</span></div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>        <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(max_new_tokens):</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>            <span class="comment"># crop idx to the last block_size tokens</span></div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>            idx_cond = idx[:, -block_size:]</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>            <span class="comment"># get the predictions</span></div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>            logits, loss = self(idx_cond)</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>            <span class="comment"># focus only on the last time step</span></div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>            logits = logits[:, -1, :]  <span class="comment"># becomes (B, C)</span></div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>            <span class="comment"># apply softmax to get probabilities</span></div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>            probs = F.softmax(logits, dim=-1)  <span class="comment"># (B, C)</span></div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>            <span class="comment"># sample from the distribution</span></div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>            idx_next = torch.multinomial(probs, num_samples=1)  <span class="comment"># (B, 1)</span></div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>            <span class="comment"># append sampled index to the running sequence</span></div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>            idx = torch.cat((idx, idx_next), dim=1)  <span class="comment"># (B, T+1)</span></div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        <span class="keywordflow">return</span> idx</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span> </div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span> </div>
</div>
</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a3a7c1fc46622cfddedb86c002e96a46a">  223</a></span>model = <a class="code hl_class" href="classworking__gpt_1_1_g_p_t_language_model.html">GPTLanguageModel</a>()</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a45bca7117bc29f8ab2d02192dbd7df1e">  224</a></span>m = model.to(device)</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span><span class="comment"># print the number of parameters in the model</span></div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>print(sum(p.numel() <span class="keywordflow">for</span> p <span class="keywordflow">in</span> m.parameters()) / 1e6, <span class="stringliteral">&quot;M parameters&quot;</span>)</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span> </div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span><span class="comment"># create a PyTorch optimizer</span></div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#abc9e178dea1174d57e7ee29d229c07f6">  229</a></span>optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span> </div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span><span class="keywordflow">for</span> iter <span class="keywordflow">in</span> range(max_iters):</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span> </div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>    <span class="comment"># every once in a while evaluate the loss on train and val sets</span></div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>    <span class="keywordflow">if</span> iter % eval_interval == 0 <span class="keywordflow">or</span> iter == max_iters - 1:</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#ac73fb870ce5fea0ba95f613b327864cf">  235</a></span>        losses = <a class="code hl_function" href="namespaceworking__gpt.html#a950488ca4171a45450e4e31f044fcaf4">estimate_loss</a>()</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>        print(</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>            f<span class="stringliteral">&quot;step {iter}: train loss {losses[&#39;train&#39;]:.4f}, val loss {losses[&#39;val&#39;]:.4f}&quot;</span></div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>        )</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span> </div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>    <span class="comment"># sample a batch of data</span></div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#ac4eb349d96fd2a82dea0e92264488cd6">  241</a></span>    xb, yb = <a class="code hl_function" href="namespaceworking__gpt.html#a537e4314706b5fa0d856cb39a9d5b974">get_batch</a>(<span class="stringliteral">&quot;train&quot;</span>)</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span> </div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    <span class="comment"># evaluate the loss</span></div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#aaa08fd2e502bf2f8ab6e9adb712ead10">  244</a></span>    logits, loss = <a class="code hl_variable" href="namespaceworking__gpt.html#a3a7c1fc46622cfddedb86c002e96a46a">model</a>(xb, yb)</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a2d7f8cbada8e08be485674ca3553552b">  245</a></span>    optimizer.zero_grad(set_to_none=<span class="keyword">True</span>)</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>    loss.backward()</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>    optimizer.step()</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span> </div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span><span class="comment"># generate from the model</span></div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno"><a class="line" href="namespaceworking__gpt.html#a36bc09e0b9c4dac0e46201ed83c06bf1">  250</a></span>context = torch.zeros((1, 1), dtype=torch.long, device=device)</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>print(<a class="code hl_variable" href="namespaceworking__gpt.html#af85d2524d40fe93c9994df5eca877ef9">decode</a>(m.generate(context, max_new_tokens=500)[0].tolist()))</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span><span class="comment"># open(&#39;more.txt&#39;, &#39;w&#39;).write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))</span></div>
<div class="ttc" id="aclassworking__gpt_1_1_block_html"><div class="ttname"><a href="classworking__gpt_1_1_block.html">working_gpt.Block</a></div><div class="ttdoc">Transformer block: communication followed by computation.</div><div class="ttdef"><b>Definition</b> <a href="#l00142">working_gpt.py:142</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_block_html_a1dfc3b1a01fca2e5f18f7efdbbe2160d"><div class="ttname"><a href="classworking__gpt_1_1_block.html#a1dfc3b1a01fca2e5f18f7efdbbe2160d">working_gpt.Block.ffwd</a></div><div class="ttdeci">ffwd</div><div class="ttdef"><b>Definition</b> <a href="#l00150">working_gpt.py:150</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_block_html_a6fd11f02e4b3567560d9c923e02eaa17"><div class="ttname"><a href="classworking__gpt_1_1_block.html#a6fd11f02e4b3567560d9c923e02eaa17">working_gpt.Block.__init__</a></div><div class="ttdeci">__init__(self, n_embd, n_head)</div><div class="ttdef"><b>Definition</b> <a href="#l00145">working_gpt.py:145</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_block_html_a75a58c24072cdc9ca6d32293751d06fb"><div class="ttname"><a href="classworking__gpt_1_1_block.html#a75a58c24072cdc9ca6d32293751d06fb">working_gpt.Block.ln2</a></div><div class="ttdeci">ln2</div><div class="ttdef"><b>Definition</b> <a href="#l00152">working_gpt.py:152</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_block_html_a89af2932fe8018bea194bc35fe7430b5"><div class="ttname"><a href="classworking__gpt_1_1_block.html#a89af2932fe8018bea194bc35fe7430b5">working_gpt.Block.forward</a></div><div class="ttdeci">forward(self, x)</div><div class="ttdef"><b>Definition</b> <a href="#l00154">working_gpt.py:154</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_block_html_aa5a75b15c13f5e1ad268693ec197a360"><div class="ttname"><a href="classworking__gpt_1_1_block.html#aa5a75b15c13f5e1ad268693ec197a360">working_gpt.Block.sa</a></div><div class="ttdeci">sa</div><div class="ttdef"><b>Definition</b> <a href="#l00149">working_gpt.py:149</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_block_html_ad3b46f9f73185d03d53d0a5f94ce42f7"><div class="ttname"><a href="classworking__gpt_1_1_block.html#ad3b46f9f73185d03d53d0a5f94ce42f7">working_gpt.Block.ln1</a></div><div class="ttdeci">ln1</div><div class="ttdef"><b>Definition</b> <a href="#l00151">working_gpt.py:151</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_feed_foward_html"><div class="ttname"><a href="classworking__gpt_1_1_feed_foward.html">working_gpt.FeedFoward</a></div><div class="ttdoc">a simple linear layer followed by a non-linearity</div><div class="ttdef"><b>Definition</b> <a href="#l00126">working_gpt.py:126</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_feed_foward_html_a4d281ee2a86f1632b7aad53e446f2680"><div class="ttname"><a href="classworking__gpt_1_1_feed_foward.html#a4d281ee2a86f1632b7aad53e446f2680">working_gpt.FeedFoward.__init__</a></div><div class="ttdeci">__init__(self, n_embd)</div><div class="ttdef"><b>Definition</b> <a href="#l00129">working_gpt.py:129</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_feed_foward_html_a92d6bf9882ff2e734975cec4598e9d51"><div class="ttname"><a href="classworking__gpt_1_1_feed_foward.html#a92d6bf9882ff2e734975cec4598e9d51">working_gpt.FeedFoward.forward</a></div><div class="ttdeci">forward(self, x)</div><div class="ttdef"><b>Definition</b> <a href="#l00138">working_gpt.py:138</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_feed_foward_html_ac1a48723779f00572e5217519e1c28eb"><div class="ttname"><a href="classworking__gpt_1_1_feed_foward.html#ac1a48723779f00572e5217519e1c28eb">working_gpt.FeedFoward.net</a></div><div class="ttdeci">net</div><div class="ttdef"><b>Definition</b> <a href="#l00131">working_gpt.py:131</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html">working_gpt.GPTLanguageModel</a></div><div class="ttdef"><b>Definition</b> <a href="#l00160">working_gpt.py:160</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_a022aa1f7826738385eb4190fe73db9fc"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#a022aa1f7826738385eb4190fe73db9fc">working_gpt.GPTLanguageModel.generate</a></div><div class="ttdeci">generate(self, idx, max_new_tokens)</div><div class="ttdef"><b>Definition</b> <a href="#l00205">working_gpt.py:205</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_a3172cb512b0556984b234c639bdc13a3"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#a3172cb512b0556984b234c639bdc13a3">working_gpt.GPTLanguageModel.lm_head</a></div><div class="ttdeci">lm_head</div><div class="ttdef"><b>Definition</b> <a href="#l00171">working_gpt.py:171</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_a6685d16c7737c65554009ab61b7ce3db"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#a6685d16c7737c65554009ab61b7ce3db">working_gpt.GPTLanguageModel.position_embedding_table</a></div><div class="ttdeci">position_embedding_table</div><div class="ttdef"><b>Definition</b> <a href="#l00166">working_gpt.py:166</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_a6bcdbf1380ac84a5c0db37f4d431db59"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#a6bcdbf1380ac84a5c0db37f4d431db59">working_gpt.GPTLanguageModel._init_weights</a></div><div class="ttdeci">_init_weights</div><div class="ttdef"><b>Definition</b> <a href="#l00174">working_gpt.py:174</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_a998f0e786960c0839f009e4613aac5ae"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#a998f0e786960c0839f009e4613aac5ae">working_gpt.GPTLanguageModel.forward</a></div><div class="ttdeci">forward(self, idx, targets=None)</div><div class="ttdef"><b>Definition</b> <a href="#l00184">working_gpt.py:184</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_aaf794f5b1d39817791387f5b51b0e547"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#aaf794f5b1d39817791387f5b51b0e547">working_gpt.GPTLanguageModel.token_embedding_table</a></div><div class="ttdeci">token_embedding_table</div><div class="ttdef"><b>Definition</b> <a href="#l00165">working_gpt.py:165</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_aaf93fa6e29338a111389f7a6fa0a35d4"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#aaf93fa6e29338a111389f7a6fa0a35d4">working_gpt.GPTLanguageModel.blocks</a></div><div class="ttdeci">blocks</div><div class="ttdef"><b>Definition</b> <a href="#l00167">working_gpt.py:167</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_ad68ec65316f6521a5109f4a1ec3e7f08"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#ad68ec65316f6521a5109f4a1ec3e7f08">working_gpt.GPTLanguageModel.__init__</a></div><div class="ttdeci">__init__(self)</div><div class="ttdef"><b>Definition</b> <a href="#l00162">working_gpt.py:162</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_g_p_t_language_model_html_ad739f9605e69c1c30950d27dc9990bc6"><div class="ttname"><a href="classworking__gpt_1_1_g_p_t_language_model.html#ad739f9605e69c1c30950d27dc9990bc6">working_gpt.GPTLanguageModel.ln_f</a></div><div class="ttdeci">ln_f</div><div class="ttdef"><b>Definition</b> <a href="#l00170">working_gpt.py:170</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_head_html"><div class="ttname"><a href="classworking__gpt_1_1_head.html">working_gpt.Head</a></div><div class="ttdoc">one head of self-attention</div><div class="ttdef"><b>Definition</b> <a href="#l00080">working_gpt.py:80</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_head_html_a12269f8694fe12099c4c2b38458f2f76"><div class="ttname"><a href="classworking__gpt_1_1_head.html#a12269f8694fe12099c4c2b38458f2f76">working_gpt.Head.key</a></div><div class="ttdeci">key</div><div class="ttdef"><b>Definition</b> <a href="#l00085">working_gpt.py:85</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_head_html_a2a84286477e3d9750c6bde3264bacec9"><div class="ttname"><a href="classworking__gpt_1_1_head.html#a2a84286477e3d9750c6bde3264bacec9">working_gpt.Head.value</a></div><div class="ttdeci">value</div><div class="ttdef"><b>Definition</b> <a href="#l00087">working_gpt.py:87</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_head_html_a2f006b42180ef31ff92582368f2fe6ca"><div class="ttname"><a href="classworking__gpt_1_1_head.html#a2f006b42180ef31ff92582368f2fe6ca">working_gpt.Head.query</a></div><div class="ttdeci">query</div><div class="ttdef"><b>Definition</b> <a href="#l00086">working_gpt.py:86</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_head_html_a362d310ec34a91843d2a4b6c997da058"><div class="ttname"><a href="classworking__gpt_1_1_head.html#a362d310ec34a91843d2a4b6c997da058">working_gpt.Head.forward</a></div><div class="ttdeci">forward(self, x)</div><div class="ttdef"><b>Definition</b> <a href="#l00092">working_gpt.py:92</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_head_html_a4a46c27cb063448efb69edd207f28e97"><div class="ttname"><a href="classworking__gpt_1_1_head.html#a4a46c27cb063448efb69edd207f28e97">working_gpt.Head.__init__</a></div><div class="ttdeci">__init__(self, head_size)</div><div class="ttdef"><b>Definition</b> <a href="#l00083">working_gpt.py:83</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_head_html_aba008c97dcdae1abdb3a1dd98d785a73"><div class="ttname"><a href="classworking__gpt_1_1_head.html#aba008c97dcdae1abdb3a1dd98d785a73">working_gpt.Head.dropout</a></div><div class="ttdeci">dropout</div><div class="ttdef"><b>Definition</b> <a href="#l00090">working_gpt.py:90</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_multi_head_attention_html"><div class="ttname"><a href="classworking__gpt_1_1_multi_head_attention.html">working_gpt.MultiHeadAttention</a></div><div class="ttdoc">multiple heads of self-attention in parallel</div><div class="ttdef"><b>Definition</b> <a href="#l00111">working_gpt.py:111</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_multi_head_attention_html_a1d8312be9b3438f1d261c634baebd247"><div class="ttname"><a href="classworking__gpt_1_1_multi_head_attention.html#a1d8312be9b3438f1d261c634baebd247">working_gpt.MultiHeadAttention.forward</a></div><div class="ttdeci">forward(self, x)</div><div class="ttdef"><b>Definition</b> <a href="#l00120">working_gpt.py:120</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_multi_head_attention_html_a507050f84e12b4708db81e3e40187c21"><div class="ttname"><a href="classworking__gpt_1_1_multi_head_attention.html#a507050f84e12b4708db81e3e40187c21">working_gpt.MultiHeadAttention.proj</a></div><div class="ttdeci">proj</div><div class="ttdef"><b>Definition</b> <a href="#l00117">working_gpt.py:117</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_multi_head_attention_html_a6a581eff19023cc386823f3159184ca2"><div class="ttname"><a href="classworking__gpt_1_1_multi_head_attention.html#a6a581eff19023cc386823f3159184ca2">working_gpt.MultiHeadAttention.heads</a></div><div class="ttdeci">heads</div><div class="ttdef"><b>Definition</b> <a href="#l00116">working_gpt.py:116</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_multi_head_attention_html_a73a6f814bfe5418a8c9c141681ca0b26"><div class="ttname"><a href="classworking__gpt_1_1_multi_head_attention.html#a73a6f814bfe5418a8c9c141681ca0b26">working_gpt.MultiHeadAttention.dropout</a></div><div class="ttdeci">dropout</div><div class="ttdef"><b>Definition</b> <a href="#l00118">working_gpt.py:118</a></div></div>
<div class="ttc" id="aclassworking__gpt_1_1_multi_head_attention_html_aee4760ff4d175b2ba2d591c33e612b2b"><div class="ttname"><a href="classworking__gpt_1_1_multi_head_attention.html#aee4760ff4d175b2ba2d591c33e612b2b">working_gpt.MultiHeadAttention.__init__</a></div><div class="ttdeci">__init__(self, num_heads, head_size)</div><div class="ttdef"><b>Definition</b> <a href="#l00114">working_gpt.py:114</a></div></div>
<div class="ttc" id="anamespaceworking__gpt_html_a3a7c1fc46622cfddedb86c002e96a46a"><div class="ttname"><a href="namespaceworking__gpt.html#a3a7c1fc46622cfddedb86c002e96a46a">working_gpt.model</a></div><div class="ttdeci">model</div><div class="ttdef"><b>Definition</b> <a href="#l00223">working_gpt.py:223</a></div></div>
<div class="ttc" id="anamespaceworking__gpt_html_a537e4314706b5fa0d856cb39a9d5b974"><div class="ttname"><a href="namespaceworking__gpt.html#a537e4314706b5fa0d856cb39a9d5b974">working_gpt.get_batch</a></div><div class="ttdeci">get_batch(split)</div><div class="ttdef"><b>Definition</b> <a href="#l00055">working_gpt.py:55</a></div></div>
<div class="ttc" id="anamespaceworking__gpt_html_a8a25d67becf5f15d2a161adb2894ef34"><div class="ttname"><a href="namespaceworking__gpt.html#a8a25d67becf5f15d2a161adb2894ef34">working_gpt.encode</a></div><div class="ttdeci">encode</div><div class="ttdef"><b>Definition</b> <a href="#l00040">working_gpt.py:40</a></div></div>
<div class="ttc" id="anamespaceworking__gpt_html_a950488ca4171a45450e4e31f044fcaf4"><div class="ttname"><a href="namespaceworking__gpt.html#a950488ca4171a45450e4e31f044fcaf4">working_gpt.estimate_loss</a></div><div class="ttdeci">estimate_loss()</div><div class="ttdef"><b>Definition</b> <a href="#l00066">working_gpt.py:66</a></div></div>
<div class="ttc" id="anamespaceworking__gpt_html_af85d2524d40fe93c9994df5eca877ef9"><div class="ttname"><a href="namespaceworking__gpt.html#af85d2524d40fe93c9994df5eca877ef9">working_gpt.decode</a></div><div class="ttdeci">str decode</div><div class="ttdef"><b>Definition</b> <a href="#l00043">working_gpt.py:43</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_c00e2513b1bc7d30539336ecc24936a2.html">gpt</a></li><li class="navelem"><a class="el" href="working__gpt_8py.html">working_gpt.py</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
