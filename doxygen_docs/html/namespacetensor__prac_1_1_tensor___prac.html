<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Transformer fundamentals: tensor_prac.Tensor_Prac Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Transformer fundamentals
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('namespacetensor__prac_1_1_tensor___prac.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">tensor_prac.Tensor_Prac Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a2e70ac6392d8f932fce031eb1f942d10" id="r_a2e70ac6392d8f932fce031eb1f942d10"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2e70ac6392d8f932fce031eb1f942d10">main</a> ()</td></tr>
<tr class="memdesc:a2e70ac6392d8f932fce031eb1f942d10"><td class="mdescLeft">&#160;</td><td class="mdescRight">Main function that loads data and demonstrates basic tensor operations.  <br /></td></tr>
<tr class="separator:a2e70ac6392d8f932fce031eb1f942d10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee8747bb0b88f4cbcb87f54134eea0d5" id="r_aee8747bb0b88f4cbcb87f54134eea0d5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aee8747bb0b88f4cbcb87f54134eea0d5">print_block_size</a> (block_size, train_data)</td></tr>
<tr class="memdesc:aee8747bb0b88f4cbcb87f54134eea0d5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prints examples of context-target pairs for given block size.  <br /></td></tr>
<tr class="separator:aee8747bb0b88f4cbcb87f54134eea0d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00e42033ea9a26eb3b31bb62acca1bbf" id="r_a00e42033ea9a26eb3b31bb62acca1bbf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a00e42033ea9a26eb3b31bb62acca1bbf">train_val_split</a> (data)</td></tr>
<tr class="memdesc:a00e42033ea9a26eb3b31bb62acca1bbf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Splits data into training and validation sets.  <br /></td></tr>
<tr class="separator:a00e42033ea9a26eb3b31bb62acca1bbf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5828c347e544b1b63727e19853f3647e" id="r_a5828c347e544b1b63727e19853f3647e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5828c347e544b1b63727e19853f3647e">get_batch</a> (batch_size, block_size, split, train_data, val_data)</td></tr>
<tr class="memdesc:a5828c347e544b1b63727e19853f3647e"><td class="mdescLeft">&#160;</td><td class="mdescRight">creates a training batch that can be stacked (better for gpus)  <br /></td></tr>
<tr class="separator:a5828c347e544b1b63727e19853f3647e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a281a9fcc00d2a9b2dbccd3251d047295" id="r_a281a9fcc00d2a9b2dbccd3251d047295"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a281a9fcc00d2a9b2dbccd3251d047295">print_training_batch</a> (input, targs, batch_size, block_size)</td></tr>
<tr class="memdesc:a281a9fcc00d2a9b2dbccd3251d047295"><td class="mdescLeft">&#160;</td><td class="mdescRight">creates a training batch that can be stacked (better for gpus)  <br /></td></tr>
<tr class="separator:a281a9fcc00d2a9b2dbccd3251d047295"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a5828c347e544b1b63727e19853f3647e" name="a5828c347e544b1b63727e19853f3647e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5828c347e544b1b63727e19853f3647e">&#9670;&#160;</a></span>get_batch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tensor_prac.Tensor_Prac.get_batch </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>batch_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>block_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>split</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>train_data</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>val_data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>creates a training batch that can be stacked (better for gpus) </p>
<p>When training data we can create a batch of block sizes to train on which is better for GPUs as they want to process multiple calcuations in one input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch_size</td><td>the size of the batch (how many independent sequences will we process in parallel) </td></tr>
    <tr><td class="paramname">block_size</td><td>the size of the context (what is the maximum context length for predictions) </td></tr>
    <tr><td class="paramname">train_data</td><td>the Tensor that stores the data used to train </td></tr>
    <tr><td class="paramname">val_data</td><td>the Tensor that stores the data used to validate </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Tuple(Tensor(batch_inputs), Tensor(batch_targets)) </dd></dl>

<p class="definition">Definition at line <a class="el" href="_tensor___prac_8py_source.html#l00110">110</a> of file <a class="el" href="_tensor___prac_8py_source.html">Tensor_Prac.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  110</span><span class="keyword">def </span>get_batch(batch_size, block_size, split, train_data, val_data):</div>
<div class="line"><span class="lineno">  111</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">    @brief creates a training batch that can be stacked (better for gpus)</span></div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">    When training data we can create a batch of block sizes to train on which is better for</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    GPUs as they want to process multiple calcuations in one input</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    @param batch_size: the size of the batch (how many independent sequences will we process in parallel)</span></div>
<div class="line"><span class="lineno">  118</span><span class="stringliteral">    @param block_size: the size of the context (what is the maximum context length for predictions)</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral">    @param train_data: the Tensor that stores the data used to train</span></div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">    @param val_data: the Tensor that stores the data used to validate</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">    @return Tuple(Tensor(batch_inputs), Tensor(batch_targets))</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  124</span>    data = train_data <span class="keywordflow">if</span> split == <span class="stringliteral">&quot;train&quot;</span> <span class="keywordflow">else</span> val_data</div>
<div class="line"><span class="lineno">  125</span>    <span class="comment"># randint will generate a random location for training</span></div>
<div class="line"><span class="lineno">  126</span>    ix = torch.randint(len(data) - block_size, (batch_size,))</div>
<div class="line"><span class="lineno">  127</span>    <span class="comment"># stack can be used to append a tensor to another</span></div>
<div class="line"><span class="lineno">  128</span>    x = torch.stack([data[i : i + block_size] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> ix])</div>
<div class="line"><span class="lineno">  129</span>    y = torch.stack([data[i + 1 : i + block_size + 1] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> ix])</div>
<div class="line"><span class="lineno">  130</span>    <span class="keywordflow">return</span> x, y</div>
<div class="line"><span class="lineno">  131</span> </div>
<div class="line"><span class="lineno">  132</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="_tensor___prac_8py_source.html#l00017">main()</a>.</p>

</div>
</div>
<a id="a2e70ac6392d8f932fce031eb1f942d10" name="a2e70ac6392d8f932fce031eb1f942d10"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2e70ac6392d8f932fce031eb1f942d10">&#9670;&#160;</a></span>main()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tensor_prac.Tensor_Prac.main </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Main function that loads data and demonstrates basic tensor operations. </p>
<p>Opens a text file, processes the data, creates training/validation splits, and demonstrates block size operations.</p>
<dl class="section return"><dt>Returns</dt><dd>None </dd></dl>

<p class="definition">Definition at line <a class="el" href="_tensor___prac_8py_source.html#l00017">17</a> of file <a class="el" href="_tensor___prac_8py_source.html">Tensor_Prac.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   17</span><span class="keyword">def </span><a class="code hl_namespace" href="namespacemain.html">main</a>():</div>
<div class="line"><span class="lineno">   18</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   19</span><span class="stringliteral">    @brief Main function that loads data and demonstrates basic tensor operations.</span></div>
<div class="line"><span class="lineno">   20</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   21</span><span class="stringliteral">    Opens a text file, processes the data, creates training/validation splits,</span></div>
<div class="line"><span class="lineno">   22</span><span class="stringliteral">    and demonstrates block size operations.</span></div>
<div class="line"><span class="lineno">   23</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   24</span><span class="stringliteral">    @return None</span></div>
<div class="line"><span class="lineno">   25</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   26</span> </div>
<div class="line"><span class="lineno">   27</span>    <span class="comment"># ensure that when data is randomly sampled we can reproduce that result</span></div>
<div class="line"><span class="lineno">   28</span>    torch.manual_seed(1337)</div>
<div class="line"><span class="lineno">   29</span>    <span class="keyword">with</span> open(os.path.dirname(__file__) + <span class="stringliteral">&quot;/../input.txt&quot;</span>, <span class="stringliteral">&quot;r&quot;</span>, encoding=<span class="stringliteral">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</div>
<div class="line"><span class="lineno">   30</span>        text = f.read()</div>
<div class="line"><span class="lineno">   31</span> </div>
<div class="line"><span class="lineno">   32</span>    print(<span class="stringliteral">&quot;length of dataset in characters: &quot;</span>, len(text))</div>
<div class="line"><span class="lineno">   33</span> </div>
<div class="line"><span class="lineno">   34</span>    print(text[:1000])</div>
<div class="line"><span class="lineno">   35</span> </div>
<div class="line"><span class="lineno">   36</span>    chars = sorted(list(set(text)))</div>
<div class="line"><span class="lineno">   37</span>    vocab_size = len(chars)</div>
<div class="line"><span class="lineno">   38</span>    print(<span class="stringliteral">&quot;&quot;</span>.join(chars))</div>
<div class="line"><span class="lineno">   39</span>    print(vocab_size)</div>
<div class="line"><span class="lineno">   40</span> </div>
<div class="line"><span class="lineno">   41</span>    <span class="comment"># create a mapping from characters to integers</span></div>
<div class="line"><span class="lineno">   42</span>    stoi = {ch: i <span class="keywordflow">for</span> i, ch <span class="keywordflow">in</span> enumerate(chars)}</div>
<div class="line"><span class="lineno">   43</span>    itos = {i: ch <span class="keywordflow">for</span> i, ch <span class="keywordflow">in</span> enumerate(chars)}</div>
<div class="line"><span class="lineno">   44</span>    <span class="comment"># encoder: takes a string, outputs a list of integers</span></div>
<div class="line"><span class="lineno">   45</span>    encode = <span class="keyword">lambda</span> s: [stoi[c] <span class="keywordflow">for</span> c <span class="keywordflow">in</span> s]</div>
<div class="line"><span class="lineno">   46</span>    <span class="comment"># decoder: take a list of strings, output the string</span></div>
<div class="line"><span class="lineno">   47</span>    decode = <span class="keyword">lambda</span> l: <span class="stringliteral">&quot;&quot;</span>.join([itos[i] <span class="keywordflow">for</span> i <span class="keywordflow">in</span> l])</div>
<div class="line"><span class="lineno">   48</span> </div>
<div class="line"><span class="lineno">   49</span>    print(encode(<span class="stringliteral">&quot;test message&quot;</span>))</div>
<div class="line"><span class="lineno">   50</span>    print(decode(encode(<span class="stringliteral">&quot;test message&quot;</span>)))</div>
<div class="line"><span class="lineno">   51</span> </div>
<div class="line"><span class="lineno">   52</span>    <span class="comment"># create a tensor representation of the encoding for all the text</span></div>
<div class="line"><span class="lineno">   53</span>    data = torch.tensor(encode(text), dtype=torch.long)</div>
<div class="line"><span class="lineno">   54</span>    print(data.shape, data.dtype)</div>
<div class="line"><span class="lineno">   55</span>    <span class="comment"># print the first 1000 elements of tensor</span></div>
<div class="line"><span class="lineno">   56</span>    print(data[:1000])</div>
<div class="line"><span class="lineno">   57</span> </div>
<div class="line"><span class="lineno">   58</span>    <span class="comment"># get the train/val split data</span></div>
<div class="line"><span class="lineno">   59</span>    train_data, val_data = train_val_split(data)</div>
<div class="line"><span class="lineno">   60</span>    print_block_size(8, train_data)</div>
<div class="line"><span class="lineno">   61</span>    input, targs = get_batch(4, 8, <span class="stringliteral">&quot;train&quot;</span>, train_data, val_data)</div>
<div class="line"><span class="lineno">   62</span>    print_training_batch(input, targs, 4, 8)</div>
<div class="line"><span class="lineno">   63</span> </div>
<div class="line"><span class="lineno">   64</span> </div>
<div class="ttc" id="anamespacemain_html"><div class="ttname"><a href="namespacemain.html">main</a></div><div class="ttdef"><b>Definition</b> <a href="main_8py_source.html#l00001">main.py:1</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_tensor___prac_8py_source.html#l00110">get_batch()</a>, <a class="el" href="_tensor___prac_8py_source.html#l00065">print_block_size()</a>, <a class="el" href="_tensor___prac_8py_source.html#l00133">print_training_batch()</a>, and <a class="el" href="_tensor___prac_8py_source.html#l00094">train_val_split()</a>.</p>

</div>
</div>
<a id="aee8747bb0b88f4cbcb87f54134eea0d5" name="aee8747bb0b88f4cbcb87f54134eea0d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee8747bb0b88f4cbcb87f54134eea0d5">&#9670;&#160;</a></span>print_block_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tensor_prac.Tensor_Prac.print_block_size </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>block_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>train_data</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Prints examples of context-target pairs for given block size. </p>
<p>Demonstrates how the context window works by showing input-output pairs for different context lengths.</p>
<p>This function will be used to print the block size for the data. Another way to describe block size is the amount of context that we will look at for each pass for our model. So in this case the block_size could be variable but for this we will fix it to 8 for this practice model</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">block_size</td><td>the size of context we want to take in </td></tr>
    <tr><td class="paramname">train_data</td><td>the training data we are using </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None </dd></dl>

<p class="definition">Definition at line <a class="el" href="_tensor___prac_8py_source.html#l00065">65</a> of file <a class="el" href="_tensor___prac_8py_source.html">Tensor_Prac.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   65</span><span class="keyword">def </span>print_block_size(block_size, train_data):</div>
<div class="line"><span class="lineno">   66</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    @brief Prints examples of context-target pairs for given block size.</span></div>
<div class="line"><span class="lineno">   68</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   69</span><span class="stringliteral">    Demonstrates how the context window works by showing input-output pairs</span></div>
<div class="line"><span class="lineno">   70</span><span class="stringliteral">    for different context lengths.</span></div>
<div class="line"><span class="lineno">   71</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">    This function will be used to print the block size for the data.</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">    Another way to describe block size is the amount of context that</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">    we will look at for each pass for our model. So in this case the</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">    block_size could be variable but for this we will fix it to 8 for</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">    this practice model</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">    @param block_size: the size of context we want to take in</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">    @param train_data: the training data we are using</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">    @return None</span></div>
<div class="line"><span class="lineno">   81</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   82</span>    print(train_data[: block_size + 1])</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span>    <span class="comment"># x will be used at training data and compared against y which is the</span></div>
<div class="line"><span class="lineno">   85</span>    <span class="comment"># actual next token</span></div>
<div class="line"><span class="lineno">   86</span>    x = train_data[:block_size]</div>
<div class="line"><span class="lineno">   87</span>    y = train_data[1 : block_size + 1]</div>
<div class="line"><span class="lineno">   88</span>    <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(block_size):</div>
<div class="line"><span class="lineno">   89</span>        context = x[: t + 1]</div>
<div class="line"><span class="lineno">   90</span>        target = y[t]</div>
<div class="line"><span class="lineno">   91</span>        print(f<span class="stringliteral">&quot;when input is {context} the target: {target}&quot;</span>)</div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="_tensor___prac_8py_source.html#l00017">main()</a>.</p>

</div>
</div>
<a id="a281a9fcc00d2a9b2dbccd3251d047295" name="a281a9fcc00d2a9b2dbccd3251d047295"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a281a9fcc00d2a9b2dbccd3251d047295">&#9670;&#160;</a></span>print_training_batch()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tensor_prac.Tensor_Prac.print_training_batch </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>input</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>targs</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>batch_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>block_size</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>creates a training batch that can be stacked (better for gpus) </p>
<p>When training data we can create a batch of block sizes to train on which is better for GPUs as they want to process multiple calcuations in one input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>the input batch tensor </td></tr>
    <tr><td class="paramname">targs</td><td>the output batch tensor </td></tr>
    <tr><td class="paramname">batch_size</td><td>the batch_size of our input tensors </td></tr>
    <tr><td class="paramname">block_size</td><td>the batch_size of our model </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None </dd></dl>

<p class="definition">Definition at line <a class="el" href="_tensor___prac_8py_source.html#l00133">133</a> of file <a class="el" href="_tensor___prac_8py_source.html">Tensor_Prac.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  133</span><span class="keyword">def </span>print_training_batch(input, targs, batch_size, block_size):</div>
<div class="line"><span class="lineno">  134</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral">    @brief creates a training batch that can be stacked (better for gpus)</span></div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  137</span><span class="stringliteral">    When training data we can create a batch of block sizes to train on which is better for</span></div>
<div class="line"><span class="lineno">  138</span><span class="stringliteral">    GPUs as they want to process multiple calcuations in one input</span></div>
<div class="line"><span class="lineno">  139</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral">    @param input: the input batch tensor</span></div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">    @param targs: the output batch tensor</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">    @param batch_size: the batch_size of our input tensors</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">    @param block_size: the batch_size of our model</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">    @return None</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  147</span>    print()</div>
<div class="line"><span class="lineno">  148</span>    print(<span class="stringliteral">&quot;inputs:&quot;</span>)</div>
<div class="line"><span class="lineno">  149</span>    print(input.shape)</div>
<div class="line"><span class="lineno">  150</span>    print(input)</div>
<div class="line"><span class="lineno">  151</span>    print(<span class="stringliteral">&quot;targets:&quot;</span>)</div>
<div class="line"><span class="lineno">  152</span>    print(targs.shape)</div>
<div class="line"><span class="lineno">  153</span>    print(targs)</div>
<div class="line"><span class="lineno">  154</span>    print(<span class="stringliteral">&quot;---------&quot;</span>)</div>
<div class="line"><span class="lineno">  155</span>    <span class="comment"># this is how we would traverse this batch tensor (it&#39;s basically a matrix)</span></div>
<div class="line"><span class="lineno">  156</span>    <span class="keywordflow">for</span> b <span class="keywordflow">in</span> range(batch_size):</div>
<div class="line"><span class="lineno">  157</span>        <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(block_size):</div>
<div class="line"><span class="lineno">  158</span>            context = input[b, : t + 1]</div>
<div class="line"><span class="lineno">  159</span>            target = targs[b, t]</div>
<div class="line"><span class="lineno">  160</span>            print(f<span class="stringliteral">&quot;when input is {context.tolist()} the target: {target}&quot;</span>)</div>
<div class="line"><span class="lineno">  161</span> </div>
<div class="line"><span class="lineno">  162</span>    <span class="comment"># seed for this because we want to make it random but reproducable</span></div>
<div class="line"><span class="lineno">  163</span> </div>
<div class="line"><span class="lineno">  164</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="_tensor___prac_8py_source.html#l00017">main()</a>.</p>

</div>
</div>
<a id="a00e42033ea9a26eb3b31bb62acca1bbf" name="a00e42033ea9a26eb3b31bb62acca1bbf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00e42033ea9a26eb3b31bb62acca1bbf">&#9670;&#160;</a></span>train_val_split()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">tensor_prac.Tensor_Prac.train_val_split </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>data</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Splits data into training and validation sets. </p>
<p>Creates a 90%/10% split between training and validation data.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>Full dataset tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Tuple of (train_data, val_data) </dd></dl>

<p class="definition">Definition at line <a class="el" href="_tensor___prac_8py_source.html#l00094">94</a> of file <a class="el" href="_tensor___prac_8py_source.html">Tensor_Prac.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   94</span><span class="keyword">def </span>train_val_split(data):</div>
<div class="line"><span class="lineno">   95</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   96</span><span class="stringliteral">    @brief Splits data into training and validation sets.</span></div>
<div class="line"><span class="lineno">   97</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">    Creates a 90%/10% split between training and validation data.</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    @param data: Full dataset tensor</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">    @return Tuple of (train_data, val_data)</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  103</span> </div>
<div class="line"><span class="lineno">  104</span>    n = int(0.9 * len(data))</div>
<div class="line"><span class="lineno">  105</span>    train_data = data[:n]</div>
<div class="line"><span class="lineno">  106</span>    val_data = data[n:]</div>
<div class="line"><span class="lineno">  107</span>    <span class="keywordflow">return</span> train_data, val_data</div>
<div class="line"><span class="lineno">  108</span> </div>
<div class="line"><span class="lineno">  109</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="_tensor___prac_8py_source.html#l00017">main()</a>.</p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacetensor__prac.html">tensor_prac</a></li><li class="navelem"><a class="el" href="namespacetensor__prac_1_1_tensor___prac.html">Tensor_Prac</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
